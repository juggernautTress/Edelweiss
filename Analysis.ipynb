{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Import libraries\nfrom scipy import stats\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style(\"white\")\nsns.set(style=\"ticks\", color_codes=True)\n%matplotlib inline\nfrom sklearn.model_selection import learning_curve, validation_curve, cross_val_score\n\n# Create table for missing data analysis\ndef draw_missing_data_table(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\n\n# missing data\ndef find_missing_data(df):\n    #missing data\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    if missing_data['Total'].max() > 0: print (missing_data.head(20))\n    else: print (\"No missing data.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8560ce4012672e539674110d5cacc4b8e6020409"
      },
      "cell_type": "markdown",
      "source": "**Load Data and Explore **\n\n\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f4e47f83916b73107cc496a277a20a0b8e380a0c"
      },
      "cell_type": "code",
      "source": "# Input data files are available in the \"../input/\" directory.\nbckgrnd = pd.read_excel('../input/UC1.xlsx', 'Background', index_col=None)\nflwseeds = pd.read_excel('../input/UC1.xlsx', 'Data', index_col=None)\n# bckgrnd.dropna(axis=0, how='all') #remve all row where all value is 'NaN' exists\n# Any results will be writen to the current directory are saved as output.\nflwseeds.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "flwseeds = flwseeds.drop([\"Unnamed: 0\"], axis=1)\nflwseeds.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "15867c66a7543d23574482eccb28712edddfe6af"
      },
      "cell_type": "markdown",
      "source": "*Check for missing data*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f206ff114ea868edef42484168e941040f56f31a"
      },
      "cell_type": "code",
      "source": "draw_missing_data_table(flwseeds) ## None",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10c34f5f161b6d431cb399651d89f8c28a30fd6c"
      },
      "cell_type": "code",
      "source": "flwseeds[\"STORE CODE\"].unique().size ## all unique store codes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5c01cf80ca7d7f6d3d67f44477bf289541d58eb3"
      },
      "cell_type": "markdown",
      "source": "*Distribution Plots*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5da94ea8481644a2f421f165cca38d02045d7a6b"
      },
      "cell_type": "code",
      "source": "initStats = flwseeds.describe()\ninitStats = initStats.drop(columns =[\"STORE CODE\"])\ninitStats",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd91dab23ca319b48ede5b8620f8940460afa979"
      },
      "cell_type": "code",
      "source": "flw_names = list(flwseeds.columns.values)[1:]\n\ninitStats = pd.DataFrame(columns=[\"mean\",\"std\"])\ninitStats[\"mean\"]=flwseeds.drop(columns =[\"STORE CODE\"]).mean();\ninitStats[\"std\"]=flwseeds.drop(columns =[\"STORE CODE\"]).std();\ninitStats[\"count\"]=flwseeds.drop(columns =[\"STORE CODE\"]).sum();\ninitStats[\"Name\"]=flw_names\n# sort df by Count column\ninitStats = initStats.sort_values(['mean'], ascending=False).reset_index(drop=True)\n\nf, ax = plt.subplots(figsize=(8, 18))\nsns.barplot(initStats[\"mean\"],initStats.Name,palette=\"Blues_d\")\n\n# print (\"Most uncommon seeds: \\n\",initStats.tail(20))\ninitStats.tail(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ef9532ab8da91b2655950d7e040b2b61fc791dd"
      },
      "cell_type": "markdown",
      "source": "Everybody orders Alyssum Y. and more than 95% order Calendula Gold, Marigold Jafri Black, Anthurium Mix, Cleome Rose, Linum Blue, Holly Hock, Sweet Pea Mix, Cereopsis, Sweet Pea Pink, Sweet Pea White and Delphinium. The rest of the flowers on the list would benefit most from sale recommendations."
    },
    {
      "metadata": {
        "_uuid": "27a971c39bcf559bb66ba6e79ffe528ef92b343e"
      },
      "cell_type": "markdown",
      "source": "*Correlation Matrix*"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71f4af253c2179bae3ba04a39ffa2340769f1c1f"
      },
      "cell_type": "code",
      "source": "flw_train = flwseeds.loc[:,flw_names]\ncorrmat = flw_train.corr(method='pearson')\nf, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(corrmat, square=True)#,annot=True);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "323fab3efb80ebaf03419351a1b9e1abbfc4df40"
      },
      "cell_type": "markdown",
      "source": "1. Recommendations based on **Pearsons' R** values"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0dcae184380f24d5468b4288383d6e7a127867e"
      },
      "cell_type": "code",
      "source": "print(initStats.loc[initStats['Name'] == \"Marigold Jafri Black\"][\"mean\"].values[0] )\ndef recommend(FlowerName, min_count):\n    print(\"For flower seed ({})\".format(FlowerName))\n    print(\"- Top 10 seed recommendation based on Pearsons'R correlation - \")\n\n    target = flw_train[FlowerName]\n    similar_to_target = flw_train.corrwith(target)\n    corr_target = pd.DataFrame(similar_to_target, columns = ['PearsonR'])\n    corr_target.dropna(inplace = True)\n    corr_target = corr_target.sort_values('PearsonR', ascending = False)\n    popularity = []\n    for idx in corr_target.index.values:\n        popularity.append(initStats.loc[initStats[\"Name\"] == idx][\"mean\"].values[0] *100.)\n    corr_target['Popularity (Seed Sale %)'] = popularity\n    print(corr_target.head(10))    \n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3a968f245cc9a99102d408d81a67c6bced88dda0"
      },
      "cell_type": "code",
      "source": "recommend(\"Calendula Gold\", 10) #popular seed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93498ec5f9d324f31535a5bd63dc1f1081318ef7"
      },
      "cell_type": "code",
      "source": "recommend(\"Petunia Purple\", 10) # uncommon seed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "695ce3ab9cb9a247bd877bff6e7ace09d9bb946b"
      },
      "cell_type": "markdown",
      "source": "To make seed recommendations: "
    },
    {
      "metadata": {
        "_uuid": "64a9a4f192138bdc6a94c5210efd147d82668a32"
      },
      "cell_type": "markdown",
      "source": "2. SVD\nSVD handles the problem of scalability and sparsity posed by CF successfully. However, SVD is not without flaw. The main drawback of SVD is that there is no to little explanation to the reason that we recommend an item to an user. This can be a huge problem if users are eager to know why a specific item is recommended to them."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75ab88a79d14b0f9a99441cc5211771d2e4a630e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8bb6bfad2d7f77526b37f9056c857f18fa2c30d0"
      },
      "cell_type": "markdown",
      "source": "**Edelweiss wants this recommendation to be statistically correct. They also want to see if this data is meaningful enough to generate some decent recommendation or not. If Kayla says that this data is insufficient, then she needs to validate that with some statistical results. They also would want to see some stores and some seeds where they should focus primarily. Other than this analysis, if the Edelweiss CEO likes the approach, then he would want to do a pilot of a few stores. Kayla should help the CEO to selct store list along with the recommnedations.**"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
